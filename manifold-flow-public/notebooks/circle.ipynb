{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy study: Gaussian on a circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import logging\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from manifold_flow import transforms, utils, distributions\n",
    "from experiments import training\n",
    "from manifold_flow.flows import Flow, ManifoldFlow\n",
    "from manifold_flow import nn as nn_\n",
    "from experiments.datasets import SphericalGaussianSimulator\n",
    "from experiments.architectures.vector_transforms import create_vector_transform\n",
    "import plot_settings as ps\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)-5.5s %(name)-30.30s %(levelname)-7.7s %(message)s\",\n",
    "    datefmt=\"%H:%M\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "# Output of all other modules (e.g. matplotlib)\n",
    "for key in logging.Logger.manager.loggerDict:\n",
    "    if \"experiments\" not in key and \"manifold_flow\" not in key:\n",
    "        logging.getLogger(key).setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 12\n",
    "n_train = 10000\n",
    "epsilon = 0.01\n",
    "train = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = SphericalGaussianSimulator(latent_dim=1, data_dim=2, epsilon=epsilon)\n",
    "x_sim = simulator.sample(n_train)\n",
    "x_sim_tensor = torch.from_numpy(x_sim)\n",
    "train_dataset = TensorDataset(x_sim_tensor, x_sim_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = OrderedDict()\n",
    "labels[\"truth\"] = \"Truth\"\n",
    "labels[\"sf\"] = \"AF\"\n",
    "labels[\"pie\"] = \"PIE (manifold)\"\n",
    "labels[\"pie_full\"] = \"PIE\"\n",
    "labels[\"mf\"] = \"FOM\"\n",
    "labels[\"mlfl\"] = r\"$\\mathcal{M}$-flow (S)\"\n",
    "labels[\"mlfa\"] = r\"$\\mathcal{M}$-flow (M/D)\"\n",
    "labels[\"mlfot\"] = r\"$\\mathcal{M}$-flow (OT)\"\n",
    "labels[\"mlfae\"] = r\"$\\mathcal{M}$-flow (AE)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = Flow(\n",
    "    data_dim=2,\n",
    "    transform=create_vector_transform(2, 10, base_transform_type=\"affine-coupling\"),\n",
    ")\n",
    "\n",
    "if train:\n",
    "    trainer = training.trainer.ForwardTrainer(sf)\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.nll],\n",
    "        loss_weights=[1.],\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    torch.save(sf.state_dict(), \"../data/models/sf_toy.pt\")\n",
    "else:\n",
    "    sf.load_state_dict(torch.load(\"../data/models/sf_toy.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifold flow (with specified manifold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    inner_transform=transforms.ConditionalAffineScalarTransform(features=1),\n",
    "    outer_transform=transforms.SphericalCoordinates(n=1, r0=1., azimuthal_offset=-0.5*np.pi)\n",
    ")\n",
    "\n",
    "if train:\n",
    "    trainer = training.trainer.ForwardTrainer(mf)\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.nll],\n",
    "        loss_weights=[1.],\n",
    "        epochs=epochs,\n",
    "        forward_kwargs={\"mode\":\"mf\"}\n",
    "    )\n",
    "    torch.save(mf.state_dict(), \"../data/models/mf_toy.pt\")\n",
    "else:\n",
    "    mf.load_state_dict(torch.load(\"../data/models/mf_toy.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    outer_transform=create_vector_transform(2, 5, base_transform_type=\"affine-coupling\"),\n",
    "    inner_transform=transforms.ConditionalAffineScalarTransform(features=1),\n",
    "    pie_epsilon=0.1,\n",
    ")\n",
    "\n",
    "if train:\n",
    "    trainer = training.trainer.ForwardTrainer(pie)\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.nll],\n",
    "        loss_weights=[1.],\n",
    "        epochs=epochs,\n",
    "        forward_kwargs={\"mode\":\"pie\"}\n",
    "    )\n",
    "    torch.save(pie.state_dict(), \"../data/models/pie_toy.pt\")\n",
    "else:\n",
    "    pie.load_state_dict(torch.load(\"../data/models/pie_toy.pt\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M-flow (alternating M/D training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlfa = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    inner_transform=transforms.ConditionalAffineScalarTransform(features=1),\n",
    "    outer_transform=create_vector_transform(2, 5, base_transform_type=\"affine-coupling\")\n",
    ")\n",
    "\n",
    "if train:\n",
    "    trainer = training.ForwardTrainer(mlfa)\n",
    "    metatrainer = training.AlternatingTrainer(mlfa, trainer, trainer)\n",
    "    metatrainer.train(\n",
    "        train_dataset,\n",
    "        loss_functions=[training.losses.mse, training.losses.nll],\n",
    "        loss_function_trainers=[0, 1],\n",
    "        loss_labels=[\"MSE\", \"NLL\"],\n",
    "        loss_weights=[100., 0.1],\n",
    "        epochs=epochs,\n",
    "        parameters=[mlfa.parameters(), mlfa.inner_transform.parameters()],\n",
    "        trainer_kwargs=[{\"forward_kwargs\": {\"mode\": \"projection\"}}, {\"forward_kwargs\": {\"mode\": \"pie\"}}],\n",
    "    )\n",
    "    torch.save(mlfa.state_dict(), \"../data/models/mlfa_toy.pt\")\n",
    "else:\n",
    "    mlfa.load_state_dict(torch.load(\"../data/models/mlfa_toy.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M-flow (OT training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlfot = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    inner_transform=transforms.ConditionalAffineScalarTransform(features=1),\n",
    "    outer_transform=create_vector_transform(2, 5, base_transform_type=\"affine-coupling\")\n",
    ")\n",
    "\n",
    "if train:\n",
    "    trainer = training.trainer.AdversarialTrainer(mlfot)\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.make_sinkhorn_divergence()],\n",
    "        loss_weights=[100.],\n",
    "        epochs=epochs,\n",
    "        batch_size=1000,\n",
    "    )\n",
    "    torch.save(mlfot.state_dict(), \"../data/models/mlfot_toy.pt\")\n",
    "else:\n",
    "    mlfot.load_state_dict(torch.load(\"../data/models/mlfot_toy.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M-flow (simple autoencoder training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlfae = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    inner_transform=transforms.ConditionalAffineScalarTransform(features=1),\n",
    "    outer_transform=create_vector_transform(2, 5, base_transform_type=\"affine-coupling\")\n",
    ")\n",
    "\n",
    "if train:\n",
    "    trainer = training.trainer.ForwardTrainer(mlfae)\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.mse],\n",
    "        loss_weights=[100.],\n",
    "        epochs=epochs,\n",
    "        forward_kwargs={\"mode\":\"projection\"}\n",
    "    )\n",
    "    torch.save(mlfae.state_dict(), \"../data/models/mlfae_toy.pt\")\n",
    "else:\n",
    "    mlfae.load_state_dict(torch.load(\"../data/models/mlfae_toy.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.eval()\n",
    "mf.eval()\n",
    "pie.eval()\n",
    "mlfa.eval()\n",
    "mlfot.eval()\n",
    "mlfae.eval()\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = OrderedDict()\n",
    "\n",
    "x_gen[\"truth\"] = x_sim[:1000]\n",
    "x_gen[\"sf\"] = sf.sample(n=1000).detach().numpy()\n",
    "x_gen[\"mf\"] = mf.sample(n=1000).detach().numpy()\n",
    "x_gen[\"pie\"] = pie.sample(n=1000).detach().numpy()\n",
    "x_gen[\"pie_full\"] = pie.sample(n=1000, sample_orthogonal=True).detach().numpy()\n",
    "# x_gen[\"mlfl\"] = mlfl.sample(n=1000).detach().numpy()\n",
    "x_gen[\"mlfa\"] = mlfa.sample(n=1000).detach().numpy()\n",
    "x_gen[\"mlfot\"] = mlfot.sample(n=1000).detach().numpy()\n",
    "x_gen[\"mlfae\"] = mlfae.sample(n=1000).detach().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model likelihood over data space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 200\n",
    "boundary = 1.5\n",
    "im_extent = boundary + 0.5 * (2.*boundary/(res - 1))\n",
    "\n",
    "x_range = np.linspace(-boundary, boundary, res)\n",
    "y_range = np.linspace(-boundary, boundary, res)\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "x_grid = np.concatenate((xx.reshape((-1,1)), yy.reshape((-1,1))), axis=1)\n",
    "x_grid_tensor = torch.FloatTensor(x_grid)\n",
    "\n",
    "\n",
    "logp_grid = OrderedDict()\n",
    "logp_grid[\"truth\"] = simulator.log_density(x_grid).reshape((res, res))\n",
    "logp_grid[\"truth\"][~np.isfinite(logp_grid[\"truth\"])] = -1000000.\n",
    "logp_grid[\"sf\"] = sf.log_prob(x_grid_tensor).detach().numpy().reshape((res, res))\n",
    "logp_grid[\"pie_full\"] = pie.log_prob(x_grid_tensor, mode=\"pie\").detach().numpy().reshape((res, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_along_manifold(model, mode=\"mf\", zmin=-5., zmax=5., n_samples=100, epsilon=0.01, max_insert=10000):\n",
    "    # Sample\n",
    "    u = torch.linspace(zmin, zmax, n_samples).view(-1,1)\n",
    "    x = model.sample(n=n_samples, u=u).detach().numpy()\n",
    "    u = u.numpy().flatten()\n",
    "    \n",
    "    def in_box(x):\n",
    "        return np.abs(x[0]) < 1.5 and np.abs(x[1]) < 1.5\n",
    "    \n",
    "    # Interpolate\n",
    "    x_interpol = [x[0]]\n",
    "    for x_prev, x_now, u_prev, u_now  in zip(x[:-1], x[1:], u[:-1], u[1:]):\n",
    "        \n",
    "        # Check if we should generate more points in between\n",
    "        distance = np.linalg.norm(x_now-x_prev)\n",
    "        if distance > epsilon and (in_box(x_now) or in_box(x_prev)):\n",
    "            n_insert = min(int(distance / epsilon), max_insert)\n",
    "            u_insert = torch.linspace(u_prev, u_now, n_insert + 2)[1:-1].view(-1,1)\n",
    "            x_insert = model.sample(n=n_insert, u=u_insert).detach().numpy()\n",
    "            for x_ in x_insert:\n",
    "                if in_box(x_):\n",
    "                    x_interpol.append(x_)\n",
    "            \n",
    "        if in_box(x_now):\n",
    "            x_interpol.append(x_now)\n",
    "            \n",
    "    x_interpol = np.array(x_interpol)\n",
    "\n",
    "    # Evaluate likelihood\n",
    "    log_probs = model.log_prob(torch.FloatTensor(x_interpol), mode=mode).detach().numpy()\n",
    "\n",
    "    # Return\n",
    "    return x_interpol, log_probs\n",
    "\n",
    "\n",
    "logp_manifold, x_manifold = OrderedDict(), OrderedDict()\n",
    "x_manifold[\"mf\"], logp_manifold[\"mf\"] = likelihood_along_manifold(mf)\n",
    "# x_manifold[\"mlfl\"], logp_manifold[\"mlfl\"] = likelihood_along_manifold(mlfl)\n",
    "x_manifold[\"mlfa\"], logp_manifold[\"mlfa\"] = likelihood_along_manifold(mlfa)\n",
    "x_manifold[\"mlfot\"], logp_manifold[\"mlfot\"] = likelihood_along_manifold(mlfot)\n",
    "x_manifold[\"mlfae\"], logp_manifold[\"mlfae\"] = likelihood_along_manifold(mlfae)\n",
    "x_manifold[\"pie\"], logp_manifold[\"pie\"] = likelihood_along_manifold(pie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate metrics for generated samples: mean distance from manifold, true likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generative_metrics(x, logp_min=-100., d_max=1., summary_fn=np.mean):\n",
    "    logp_gen = simulator.log_density(x)\n",
    "    logp_gen[(~np.isfinite(logp_gen)) + (logp_gen<logp_min)] = logp_min\n",
    "    logp_summary = summary_fn(logp_gen)\n",
    "    \n",
    "    d_gen = np.abs(np.sum(x**2, axis=1)**0.5 - 1)\n",
    "    d_gen[(~np.isfinite(d_gen)) + (d_gen>d_max)] = d_max\n",
    "    d_summary = summary_fn(d_gen)\n",
    "    \n",
    "    return logp_summary, d_summary\n",
    "\n",
    "\n",
    "logp_gen, d_gen = OrderedDict(), OrderedDict()\n",
    "\n",
    "for key, val in x_gen.items():\n",
    "    logp_gen[key], d_gen[key] = generative_metrics(x_gen[key])\n",
    "    \n",
    "\n",
    "print(\"Mean true log likelihood of samples generated from flows (higher is better):\")\n",
    "for key, val in logp_gen.items():\n",
    "    print(\"  {:>10.10s}: {:>6.1f}\".format(key, val))\n",
    "    \n",
    "print(\"Mean Euclidean distance between samples generated from flows and true manifold (lower is better):\")\n",
    "for key, val in d_gen.items():\n",
    "    print(\"  {:>10.10s}: {:>6.4f}\".format(key, val))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "show1 = [\"truth\", \"sf\", \"pie\", \"mf\", \"mlfa\", \"mlfot\"]\n",
    "show2 = [None, None, \"pie_full\", None, None, \"mlfae\"]\n",
    "\n",
    "fig = plt.figure(figsize=(4.*3,4.*2))\n",
    "\n",
    "for i, (key, key2) in enumerate(zip(show1, show2)):\n",
    "    ax = plt.subplot(2,3,i+1)\n",
    "    \n",
    "    if key2 is not None:\n",
    "        plt.scatter(x_gen[key2][:n,0], x_gen[key2][:n,1], s=6., c=\"C1\", label=labels[key2])\n",
    "    plt.scatter(x_gen[key][:n,0], x_gen[key][:n,1], s=6., c=\"C3\", label=labels[key])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlim(-boundary, boundary)\n",
    "    plt.ylim(-boundary, boundary)\n",
    "    plt.xlabel(\"$x_1$\")\n",
    "    plt.ylabel(\"$x_2$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/circle_generated_samples.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = [\"truth\", \"sf\", \"pie_full\", \"mf\", \"mlfa\", \"mlfae\"]\n",
    "cmins = [-6., -6., -6., -5., -5., -5.]\n",
    "cmaxs = [1.5, 1.5, 1.5, -0.5, -0.5, -0.5]\n",
    "\n",
    "label_kwargs={\"ha\":\"left\", \"va\":\"top\", \"x\":-1.4, \"y\":1.4, \"fontsize\":9., \"fontweight\":\"500\"}\n",
    "\n",
    "fig, gs = ps.grid2_width(3, 2, small_margin=0.01, large_margin=0.085)\n",
    "\n",
    "for i, (key, cmin, cmax) in enumerate(zip(show, cmins, cmaxs)):\n",
    "    panel = i if i < 3 else i+1\n",
    "    ax = plt.subplot(gs[panel])\n",
    "    \n",
    "    try:\n",
    "        x = x_manifold[key]\n",
    "        logp = logp_manifold[key]\n",
    "        \n",
    "        for increase_size in [0.01, 0.]:\n",
    "            segments = np.concatenate([x[:-1,np.newaxis,:], x[1:,np.newaxis,:]], axis=1)\n",
    "            segments = [\n",
    "                [start - increase_size * (end - start)/np.linalg.norm(end - start),\n",
    "                 end + increase_size * (end - start)/np.linalg.norm(end - start)]\n",
    "                for (start, end) in segments\n",
    "            ]\n",
    "            lc = LineCollection(segments, cmap=ps.CMAP, norm=plt.Normalize(cmin, cmax))\n",
    "            lc.set_array(np.clip(logp, cmin, cmax))\n",
    "            lc.set_linewidth(2.5)\n",
    "            im = ax.add_collection(lc)\n",
    "        plt.text(s=labels[key], c=ps.COLOR_NEUTRAL4, **label_kwargs)\n",
    "        \n",
    "        ax.set_facecolor('black')\n",
    "\n",
    "    except KeyError:\n",
    "        logp = logp_grid[key]\n",
    "        im = plt.imshow(\n",
    "            np.clip(logp, cmin, cmax),\n",
    "            extent=(-im_extent, im_extent, -im_extent, im_extent),\n",
    "            origin=\"lower\",\n",
    "            cmap=ps.CMAP,\n",
    "            norm=matplotlib.colors.Normalize(cmin, cmax),\n",
    "            interpolation='nearest',\n",
    "            aspect=\"auto\"\n",
    "        )\n",
    "        \n",
    "        if key==\"pie_full\":\n",
    "            plt.plot(x_manifold[\"pie\"][:,0], x_manifold[\"pie\"][:,1], lw=1., ls=\":\", c=ps.COLOR_NEUTRAL1)\n",
    "            \n",
    "        plt.text(s=labels[key], c=ps.COLOR_NEUTRAL4, **label_kwargs)\n",
    "\n",
    "    plt.xlim(-im_extent, im_extent)\n",
    "    plt.ylim(-im_extent, im_extent)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "    if i in [0, 3]:\n",
    "        ax = plt.subplot(gs[4*int(i>0) + 3])\n",
    "        cbar = fig.colorbar(\n",
    "            im,\n",
    "            cax=ax,\n",
    "            extend=\"both\",\n",
    "            ticks=[-6.,-5.,-4.,-3,-2,-1,0,1],\n",
    "            #format=matplotlib.ticker.FuncFormatter(lambda x, _ : \"{:.0f}\".format(x**2))\n",
    "        )\n",
    "        cbar.set_label(r\"Log likelihood\")\n",
    "        # ax.yaxis.set_label_coords(5., 0.5)\n",
    "    \n",
    "plt.savefig(\"../figures/circle_log_likelihood.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
